{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1c0756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03737259,  0.00904254,  0.01632568, -0.00451072], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"none\")\n",
    "#gym.make(...) : Cette fonction crée un environnement de simulation. \n",
    "#CartPole-v1 est un problème de maintenir en équilibre un bâton(pole) sur un chariot(cart) en déplaçant gauche ou droite.\n",
    "#render_mode=\"human\" : Ce paramètre active le rendu visuel de l'environnement, ce qui permet de voir la simulation en temps réel dans une fenêtre graphique.\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad2b0f",
   "metadata": {},
   "source": [
    "### EXERCICE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Espace d'actions : {env.action_space}\") # décrit l'espace des actions possibles dans l'environnement.\n",
    "#Pour CartPole, il y a deux actions possibles : 0 (déplacer le chariot à gauche) et 1 (déplacer le chariot à droite).\n",
    "print(f\"Espace d'observations : {env.observation_space}\") #décrit l'espace des observations (ou états) que l'environnement peut renvoyer.\n",
    "#Pour CartPole, une observation est un tableau de 4 valeurs représentant : La position du chariot. La vitesse du chariot.\n",
    "#L'angle du bâton. La vitesse angulaire du bâton.\n",
    "\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample() # Choisit une action aléatoire dans l'espace d'actions.\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    #Exécute l'action choisie et retourne observation : L'état de l'environnement reward : La récompense obtenue\n",
    "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0771887",
   "metadata": {},
   "source": [
    "### EXERCICE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d5429",
   "metadata": {},
   "source": [
    "#### Prendre une action et récupérer les valeurs retournées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b635634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()\n",
    "observation, reward, done, _, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923d18c",
   "metadata": {},
   "source": [
    "#### Afficher ces valeurs et analyser leur signification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3d5520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : 1\n",
      "Observation : [ 0.00791414  0.23831505 -0.00837669 -0.26289147]\n",
      "Reward : 1.0\n",
      "Done : False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Action : {action}\") # 0 = gauche, 1 = droite\n",
    "print(f\"Observation : {observation}\")\n",
    "print(f\"Reward : {reward}\") # 1 chaque étape si le bâton reste en équilibre. Si la simulation se termine, la récompense est 0.\n",
    "print(f\"Done : {done}\") # True si le bâton tombe ou si le chariot sort des limites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde91ce1",
   "metadata": {},
   "source": [
    "#### Faire plusieurs essais et noter les variations des observations et des récompenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    action = env.action_space.sample() # Choisit une action aléatoire dans l'espace d'actions.\n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    #Exécute l'action choisie et retourne observation : L'état de l'environnement ,reward : La récompense obtenue\n",
    "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bd51f",
   "metadata": {},
   "source": [
    "### Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59313e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [-0.03719174  0.20392661  0.01623547 -0.2919983 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [-0.0331132   0.39881334  0.0103955  -0.5795169 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [-0.02513694  0.5937881  -0.00119484 -0.868907  ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [-0.01326117  0.78892624 -0.01857298 -1.1619654 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.00251735  0.9842851  -0.04181228 -1.4604132 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.02220305  1.1798941  -0.07102054 -1.7658594 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.04580094  1.375743   -0.10633773 -2.0797548 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.0733158   1.5717691  -0.14793283 -2.4033375 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.10475118  1.7678396  -0.19599958 -2.7375646 ]\n",
      "Done : False\n",
      "Entrez une action (0 ou 1) : 1\n",
      "Observation : [ 0.14010797  1.9637334  -0.25075087 -3.0830352 ]\n",
      "Done : True\n",
      "episode est termine apres 10 etapes.\n"
     ]
    }
   ],
   "source": [
    "etape = 0\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = input(\"Entrez une action (0 ou 1) : \")\n",
    "    action = int(action)\n",
    "    \n",
    "    observation, reward, done, _, _ = env.step(action)\n",
    "    \n",
    "    print(f\"Observation : {observation}\")\n",
    "    print(f\"Done : {done}\")\n",
    "    \n",
    "    etape += 1\n",
    "\n",
    "\n",
    "print(f\"episode est termine apres {etape} etapes.\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695686d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
